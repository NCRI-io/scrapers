{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b341b80-fcf6-490d-b0c2-0ae9b1d55a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f719da-dcf1-4ab9-be25-978584b5afa8",
   "metadata": {},
   "source": [
    "# Scrape FB Page comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf00f2-bb28-4e15-be11-0406311ac312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(fb_group_list, pages, cookies_file, options):\n",
    "    \"\"\"\n",
    "    Made this dataframe based on: https://github.com/kevinzg/facebook-scraper\n",
    "    \n",
    "    Args:\n",
    "        fb_group_list(str, list): a list of Facebook pages to scrape, must be public\n",
    "        pages(int): number of pages to collect\n",
    "        cookies_file(str): file location of cookies data\n",
    "        options(dict): dictionary of options for collection, dictionary options can be found in the link above\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: a DataFrame containing comments and associated information from posts scraped. Posts scraped are gathered from 'fb_group_list' posts that \n",
    "                   that contain words inputted in 'words_list'\n",
    "    \"\"\"\n",
    "    # If content in the 'comment_text' column is the commenters name it is most likely because they commented with just a picture and no text\n",
    "    post_list = []\n",
    "    df_comments = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            comments_list = []\n",
    "            replies_list = []\n",
    "            \n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "            x = 0\n",
    "                \n",
    "            while x < len(post_list):\n",
    "                comments_list = post_list[x]['comments_full']\n",
    "                x+=1\n",
    "\n",
    "                if comments_list != []:\n",
    "                    i = 0\n",
    "                    comment_text = comments_list[i]['comment_text']\n",
    "\n",
    "                    for comment in comment_text:\n",
    "                        while i < len(comments_list):\n",
    "                            comments_list[i]['comment_text'] = comments_list[i]['comment_text'].split('\\n',1)[0]\n",
    "                            replies_list = comments_list[i]['replies']\n",
    "                            i+=1\n",
    "\n",
    "                            if replies_list != []:\n",
    "                                z = 0\n",
    "\n",
    "                                while z < len(replies_list):\n",
    "                                    replies_list[z]['comment_text'] = replies_list[z]['comment_text'].split('\\n',1)[0]\n",
    "                                    z+=1\n",
    "            df_comments = df_comments.append(comments_list)\n",
    "    print('Done')\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264c94a5-c084-4dd4-93f4-a3a519c95d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_page_list = ['AlaskasNewsSource']\n",
    "\"\"\"\n",
    "AlaskasNewsSource, 'alaska.dhss', 'ancpublichealth', 'FairbanksMemorialHospital','voiceofcph', 'MatSuRegionalMedicalCenter',\n",
    "               'AlaskasNewsSource', 'alaskapublic', 'juneauempire', 'fairbanksDNM', 'frontiersman',\n",
    "               'NomeNuggetNews', 'HomerNews', 'sitkasentinel', 'ktvf.fairbanks', 'peninsulaclarion', 'KSRM920AM', 'KYUK', 'AnchorageSchoolDistrict',\n",
    "               'fsdk12', 'kpbsd', 'akmatsuk12', 'BethelSD', 'cbjuneau', 'MatSuBorough', 'COBarrow', 'KRBD-FM-Rainbird-Community-Radio-158267229179']\n",
    "               \"\"\"\n",
    "# Still need to get these FB pages:, Fairbanks Borough, Kenai Peninsula Borough\n",
    "cookies = ('facebook.com_cookies.txt')\n",
    "words_list = ['Covid', 'covid', 'COVID', 'Coronavirus', 'coronavirus', 'Vaccine', 'vaccine', 'Vaccination', 'vaccination', 'Omicron', 'omicron',\n",
    "             'vaccination', 'vaccinations', 'vaccines', 'shot', 'experimental', 'mask', 'masks', \n",
    "           'scamdemic', 'sterilization', 'mrna', 'fauci', 'experimental', 'flu', 'immune', \n",
    "           'ivermectin', 'symptoms', 'vax', 'mandate', 'reactions', 'asymptomatic', 'toxin',\n",
    "           'remdesivir', 'contracting', 'inject', 'pandemic', 'pandemics', 'pfizer', 'moderna', 'contagious', \n",
    "           'complications', 'strains', 'virologist', 'masking', 'compromised', 'distancing',\n",
    "           'hydroxychloroquine', 'infected', 'infections', 'infection', 'rna', 'omicron', 'delta', 'misinformation',\n",
    "           'pharmaceutical', 'mongering', 'pharma', 'viruses', 'agenda', 'antibodies', 'guniea', 'propaganda', \n",
    "           'disease', 'poison', 'symptoms', 'effective', 'jab', 'research', 'natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd0da9-2697-48f2-ba96-6e83e24d9470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = scrape_comments(fb_group_list, 10000000, cookies, {\"comments\": True, \"reactors\": True, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1582e-3779-4743-b0f3-f0dbb5a123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcd414-17f6-452b-a958-5a777ba652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4ae54-f57b-48a3-811a-8a9880d39196",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_filtered = comments[comments['comment_text'].str.contains('|'.join(words_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee5912-b46e-4159-8a8e-d6e4d92bb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_filtered.to_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3cf09-ce2f-4910-a0c5-adc852aaaba6",
   "metadata": {},
   "source": [
    "# Scrape FB Page Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb8fdbc4-1c81-458e-b577-f9fbf3557753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only collects posts\n",
    "def scrape_posts(fb_group_list, pages, cookies_file, options):\n",
    "    post_list = []\n",
    "    df_posts = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            post_list.append(post)\n",
    "        df_posts = df_posts.append(post_list)\n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fc957f8-b978-47e0-9bed-1d7ee0bbbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_group_list = ['Dartmouth-Coalition-for-Israel-Palestine-284611641585230']\n",
    "cookies = ('facebook.com_cookies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ea3c04c-d883-4354-a2f4-5791c9bce1e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/contrib/pyopenssl.py:319\u001b[0m, in \u001b[0;36mWrappedSocket.recv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenSSL\u001b[38;5;241m.\u001b[39mSSL\u001b[38;5;241m.\u001b[39mSysCallError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/SSL.py:1822\u001b[0m, in \u001b[0;36mConnection.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     result \u001b[38;5;241m=\u001b[39m _lib\u001b[38;5;241m.\u001b[39mSSL_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl, buf, nbytes)\n\u001b[0;32m-> 1822\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_ssl_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ssl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;66;03m# This strange line is all to avoid a memory copy. The buffer protocol\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# should allow us to assign a CFFI buffer to the LHS of this line, but\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;66;03m# on CPython 3.3+ that segfaults. As a workaround, we can temporarily\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;66;03m# wrap it in a memoryview.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/SSL.py:1622\u001b[0m, in \u001b[0;36mConnection._raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;241m==\u001b[39m _lib\u001b[38;5;241m.\u001b[39mSSL_ERROR_WANT_READ:\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WantReadError()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error \u001b[38;5;241m==\u001b[39m _lib\u001b[38;5;241m.\u001b[39mSSL_ERROR_WANT_WRITE:\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m posts \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfb_group_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_extra_requests\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mscrape_posts\u001b[0;34m(fb_group_list, pages, cookies_file, options)\u001b[0m\n\u001b[1;32m      4\u001b[0m df_posts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fb_group \u001b[38;5;129;01min\u001b[39;00m fb_group_list:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m get_posts(fb_group, pages \u001b[38;5;241m=\u001b[39m pages, cookies \u001b[38;5;241m=\u001b[39m cookies_file, options \u001b[38;5;241m=\u001b[39m options):\n\u001b[1;32m      7\u001b[0m         post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m         post_list\u001b[38;5;241m.\u001b[39mappend(post)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:939\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting posts from page \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post_element \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[0;32m--> 939\u001b[0m     post \u001b[38;5;241m=\u001b[39m \u001b[43mextract_post_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_element\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_source:\n\u001b[1;32m    941\u001b[0m         post\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/extractors.py:33\u001b[0m, in \u001b[0;36mextract_post\u001b[0;34m(raw_post, options, request_fn, full_post_html)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_post\u001b[39m(\n\u001b[1;32m     31\u001b[0m     raw_post: RawPost, options: Options, request_fn: RequestFunction, full_post_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Post:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPostExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_post_html\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/extractors.py:186\u001b[0m, in \u001b[0;36mPostExtractor.extract_post\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m         partial_post \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m partial_post \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m             log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract method \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt return anything\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/extractors.py:597\u001b[0m, in \u001b[0;36mPostExtractor.extract_photo_link\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m     url \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39murljoin(FB_MOBILE_BASE_URL, url)\n\u001b[1;32m    596\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 597\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m photo_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_photo_link_HQ(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m photo_link \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m images:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:699\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    697\u001b[0m     url \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39murljoin(FB_MOBILE_BASE_URL, url)\n\u001b[0;32m--> 699\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mhtml \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-->\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    701\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:546\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    545\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:533\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    531\u001b[0m }\n\u001b[1;32m    532\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 533\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:686\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 686\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:828\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:750\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 750\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    751\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py:572\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py:764\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 764\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    766\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py:694\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/contrib/pyopenssl.py:331\u001b[0m, in \u001b[0;36mWrappedSocket.recv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenSSL\u001b[38;5;241m.\u001b[39mSSL\u001b[38;5;241m.\u001b[39mWantReadError:\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m timeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe read operation timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/wait.py:146\u001b[0m, in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_read\u001b[39m(sock, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124;03m\"\"\"Waits for reading to be available on a given socket.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Returns True if the socket is readable, or False if the timeout expired.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/wait.py:107\u001b[0m, in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m         t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m poll_obj\u001b[38;5;241m.\u001b[39mpoll(t)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43m_retry_on_intr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_poll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/wait.py:43\u001b[0m, in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_on_intr\u001b[39m(fn, timeout):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/wait.py:105\u001b[0m, in \u001b[0;36mpoll_wait_for_socket.<locals>.do_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpoll_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "posts = scrape_posts(fb_group_list, 100000000, cookies, {\"comments\": True, \"allow_extra_requests\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af474e-3e67-4347-a65b-b2e683763a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73851cee-a9f8-4b25-ad7c-c75cfc746501",
   "metadata": {},
   "source": [
    "# Scrape FB group comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1801cdf0-3497-470a-9396-cbd23bf9d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(fb_group_list, pages, cookies_file, options):\n",
    "    \"\"\"\n",
    "    Made this dataframe based on: https://github.com/kevinzg/facebook-scraper\n",
    "    \n",
    "    Args:\n",
    "        fb_group_list(str, list): a list of Facebook pages to scrape, must be public\n",
    "        pages(int): number of pages to collect\n",
    "        cookies_file(str): file location of cookies data\n",
    "        options(dict): dictionary of options for collection, dictionary options can be found in the link above\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: a DataFrame containing comments and associated information from posts scraped. Posts scraped are gathered from 'fb_group_list' posts that \n",
    "                   that contain words inputted in 'words_list'\n",
    "    \"\"\"\n",
    "    # If content in the 'comment_text' column is the commenters name it is most likely because they commented with just a picture and no text\n",
    "    post_list = []\n",
    "    df_comments = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(group = fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            comments_list = []\n",
    "            replies_list = []\n",
    "            \n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "            x = 0\n",
    "                \n",
    "            while x < len(post_list):\n",
    "                comments_list = post_list[x]['comments_full']\n",
    "                x+=1\n",
    "\n",
    "                if comments_list != []:\n",
    "                    i = 0\n",
    "                    comment_text = comments_list[i]['comment_text']\n",
    "\n",
    "                    for comment in comment_text:\n",
    "                        while i < len(comments_list):\n",
    "                            comments_list[i]['comment_text'] = comments_list[i]['comment_text'].split('\\n',1)[0]\n",
    "                            replies_list = comments_list[i]['replies']\n",
    "                            i+=1\n",
    "\n",
    "                            if replies_list != []:\n",
    "                                z = 0\n",
    "\n",
    "                                while z < len(replies_list):\n",
    "                                    replies_list[z]['comment_text'] = replies_list[z]['comment_text'].split('\\n',1)[0]\n",
    "                                    z+=1\n",
    "            df_comments = df_comments.append(comments_list)\n",
    "    print('Done')\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a2400f8-f017-4235-a575-3b215c827c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_group_list = ['Dartmouth-Coalition-for-Israel-Palestine-284611641585230']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d38756b0-0b65-4591-b172-b2302a3fd695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "Content Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m comments \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfb_group_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreactors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_extra_requests\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposts_per_page\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mscrape_comments\u001b[0;34m(fb_group_list, pages, cookies_file, options)\u001b[0m\n\u001b[1;32m     17\u001b[0m df_comments \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fb_group \u001b[38;5;129;01min\u001b[39;00m fb_group_list:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m get_posts(group \u001b[38;5;241m=\u001b[39m fb_group, pages \u001b[38;5;241m=\u001b[39m pages, cookies \u001b[38;5;241m=\u001b[39m cookies_file, options \u001b[38;5;241m=\u001b[39m options):\n\u001b[1;32m     20\u001b[0m         post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m         comments_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:936\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m counter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m page_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(page_limit)\n\u001b[1;32m    935\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to iterate pages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(counter, iter_pages_fn()):\n\u001b[1;32m    937\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting posts from page \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post_element \u001b[38;5;129;01min\u001b[39;00m page:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/page_iterators.py:92\u001b[0m, in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequesting page from: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, next_url)\n\u001b[0;32m---> 92\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:741\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m not_found_titles:\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNotFound(title\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedResponse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour request couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotFound\u001b[0m: Content Not Found"
     ]
    }
   ],
   "source": [
    "comments = scrape_comments(fb_group_list, 40, cookies, {\"comments\": True, \"reactors\": True, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96039c66-0367-417c-9bd8-f63686e7ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('convoy_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2bcba-06bb-41c4-a38c-fb391ecb6725",
   "metadata": {},
   "source": [
    "# Scrape FB group posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "205af4d6-26cc-4892-86f8-aff603455839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only collects posts\n",
    "def scrape_group_posts(fb_group_list, pages, cookies_file, options):\n",
    "    post_list = []\n",
    "    df_posts = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(group = fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "        df_posts = df_posts.append(post_list)\n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd13157f-50e8-40f8-b325-f021fe7d24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_group_list = ['Dartmouth-Coalition-for-Israel-Palestine-284611641585230']\n",
    "cookies = ('facebook.com_cookies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fcd63f9-6771-40d5-8fc9-01d3a04a2a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "Content Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m group_posts \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_group_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfb_group_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_extra_requests\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposts_per_page\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mscrape_group_posts\u001b[0;34m(fb_group_list, pages, cookies_file, options)\u001b[0m\n\u001b[1;32m      4\u001b[0m df_posts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fb_group \u001b[38;5;129;01min\u001b[39;00m fb_group_list:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m get_posts(group \u001b[38;5;241m=\u001b[39m fb_group, pages \u001b[38;5;241m=\u001b[39m pages, cookies \u001b[38;5;241m=\u001b[39m cookies_file, options \u001b[38;5;241m=\u001b[39m options):\n\u001b[1;32m      7\u001b[0m         post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:936\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m counter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m page_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(page_limit)\n\u001b[1;32m    935\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to iterate pages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(counter, iter_pages_fn()):\n\u001b[1;32m    937\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting posts from page \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post_element \u001b[38;5;129;01min\u001b[39;00m page:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/page_iterators.py:92\u001b[0m, in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequesting page from: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, next_url)\n\u001b[0;32m---> 92\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:741\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m not_found_titles:\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNotFound(title\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedResponse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour request couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotFound\u001b[0m: Content Not Found"
     ]
    }
   ],
   "source": [
    "group_posts = scrape_group_posts(fb_group_list, 10000000, cookies, {\"comments\": False, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfffb87f-9a43-44d4-b775-2de3d01221e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_posts.to_csv('convoy_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75558337-a724-468e-948f-1813671148b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
