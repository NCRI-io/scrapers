{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c753d-cca2-4f5b-94a1-059c50ef6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3c1ee-a346-4c5c-9f19-c82e8e700f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_comments(fb_group_list, pages, cookies_file, options, words_list):\n",
    "    \"\"\"\n",
    "    Made this dataframe based on: https://github.com/kevinzg/facebook-scraper\n",
    "    \n",
    "    Args:\n",
    "        fb_group_list(str, list): a list of Facebook pages to scrape, must be public\n",
    "        pages(int): number of pages to collect\n",
    "        cookies_file(str): file location of cookies data\n",
    "        options(dict): dictionary of options for collection, dictionary options can be found in the link above\n",
    "        words_list(str, list): list of words to filter posts by\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: a DataFrame containing comments and associated information from posts scraped. Posts scraped are gathered from 'fb_group_list' posts that \n",
    "                   that contain words inputted in 'words_list'\n",
    "    \"\"\"\n",
    "    # If content in the 'comment_text' column is the commenters name it is most likely because they commented with just a picture and no text\n",
    "    post_list = []\n",
    "    df_comments = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            words = words_list\n",
    "            comments_list = []\n",
    "            replies_list = []\n",
    "            \n",
    "            if any(word in post['text'] for word in words) == True:\n",
    "                print(post['text']+'\\n')\n",
    "                post_list.append(post)\n",
    "                x = 0\n",
    "                #comments_list = []\n",
    "                \n",
    "                while x < len(post_list):\n",
    "                    #print(post['text'])\n",
    "                    comments_list = post_list[x]['comments_full']\n",
    "                    x+=1\n",
    "                    \n",
    "                    if comments_list != []:\n",
    "                        i = 0\n",
    "                        \n",
    "                        while i < len(comments_list):\n",
    "                            comments_list[i]['comment_text'] = comments_list[i]['comment_text'].split('\\n',1)[0]\n",
    "                            replies_list = comments_list[i]['replies']\n",
    "                            i+=1\n",
    "                            \n",
    "                            if replies_list != []:\n",
    "                                z = 0\n",
    "                                \n",
    "                                while z < len(replies_list):\n",
    "                                    replies_list[z]['comment_text'] = replies_list[z]['comment_text'].split('\\n',1)[0]\n",
    "                                    z+=1\n",
    "                            \n",
    "            df_comments = df_comments.append(comments_list)\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e0cfe-6d0f-4855-b86d-72168ee5d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_group_list = ['']\n",
    "cookies = ('')\n",
    "words_list = [']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6005bca-3d32-44bf-8415-cb819e9bf765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_comments(fb_group_list, 50, cookies, {\"comments\": True, \"allow_extra_requests\": True, 'posts_per_page': 1}, words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb26c2a-4bd6-4f1b-8666-411542efd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = scrape_comments(fb_group_list, 20, cookies, {\"comments\": True, \"allow_extra_requests\": True, 'posts_per_page': 1}, words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b197d4-ce74-4628-bf34-01344ca7f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed10b9-48eb-4b23-8c5d-e5d533cfe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper sometimes returns duplicate posts. This removes instances of the same column that appear more than once\n",
    "df_comments.drop_duplicates(subset = 'comment_id',\n",
    "                     keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c6f8c-e4b4-4c63-a720-2e1541bfe141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.to_csv('df_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
