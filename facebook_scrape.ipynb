{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b341b80-fcf6-490d-b0c2-0ae9b1d55a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f719da-dcf1-4ab9-be25-978584b5afa8",
   "metadata": {},
   "source": [
    "# Scrape FB Page comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf00f2-bb28-4e15-be11-0406311ac312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(fb_group_list, pages, cookies_file, options):\n",
    "    \"\"\"\n",
    "    Made this dataframe based on: https://github.com/kevinzg/facebook-scraper\n",
    "    \n",
    "    Args:\n",
    "        fb_group_list(str, list): a list of Facebook pages to scrape, must be public\n",
    "        pages(int): number of pages to collect\n",
    "        cookies_file(str): file location of cookies data\n",
    "        options(dict): dictionary of options for collection, dictionary options can be found in the link above\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: a DataFrame containing comments and associated information from posts scraped. Posts scraped are gathered from 'fb_group_list' posts that \n",
    "                   that contain words inputted in 'words_list'\n",
    "    \"\"\"\n",
    "    # If content in the 'comment_text' column is the commenters name it is most likely because they commented with just a picture and no text\n",
    "    post_list = []\n",
    "    df_comments = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            comments_list = []\n",
    "            replies_list = []\n",
    "            \n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "            x = 0\n",
    "                \n",
    "            while x < len(post_list):\n",
    "                comments_list = post_list[x]['comments_full']\n",
    "                x+=1\n",
    "\n",
    "                if comments_list != []:\n",
    "                    i = 0\n",
    "                    comment_text = comments_list[i]['comment_text']\n",
    "\n",
    "                    for comment in comment_text:\n",
    "                        while i < len(comments_list):\n",
    "                            comments_list[i]['comment_text'] = comments_list[i]['comment_text'].split('\\n',1)[0]\n",
    "                            replies_list = comments_list[i]['replies']\n",
    "                            i+=1\n",
    "\n",
    "                            if replies_list != []:\n",
    "                                z = 0\n",
    "\n",
    "                                while z < len(replies_list):\n",
    "                                    replies_list[z]['comment_text'] = replies_list[z]['comment_text'].split('\\n',1)[0]\n",
    "                                    z+=1\n",
    "            df_comments = df_comments.append(comments_list)\n",
    "    print('Done')\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c94a5-c084-4dd4-93f4-a3a519c95d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_page_list = ['']\n",
    "cookies = ('')\n",
    "words_list = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd0da9-2697-48f2-ba96-6e83e24d9470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = scrape_comments(fb_group_list, 10000000, cookies, {\"comments\": True, \"reactors\": True, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1582e-3779-4743-b0f3-f0dbb5a123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcd414-17f6-452b-a958-5a777ba652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4ae54-f57b-48a3-811a-8a9880d39196",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_filtered = comments[comments['comment_text'].str.contains('|'.join(words_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee5912-b46e-4159-8a8e-d6e4d92bb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_filtered.to_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3cf09-ce2f-4910-a0c5-adc852aaaba6",
   "metadata": {},
   "source": [
    "# Scrape FB Page Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fdbc4-1c81-458e-b577-f9fbf3557753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only collects posts\n",
    "def scrape_posts(fb_group_list, pages, cookies_file, options):\n",
    "    post_list = []\n",
    "    df_posts = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            post_list.append(post)\n",
    "        df_posts = df_posts.append(post_list)\n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc957f8-b978-47e0-9bed-1d7ee0bbbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_group_list = ['']\n",
    "cookies = ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3c04c-d883-4354-a2f4-5791c9bce1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = scrape_posts(fb_group_list, 100000000, cookies, {\"comments\": True, \"allow_extra_requests\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af474e-3e67-4347-a65b-b2e683763a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73851cee-a9f8-4b25-ad7c-c75cfc746501",
   "metadata": {},
   "source": [
    "# Scrape FB group comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801cdf0-3497-470a-9396-cbd23bf9d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(fb_group_list, pages, cookies_file, options):\n",
    "    \"\"\"\n",
    "    Made this dataframe based on: https://github.com/kevinzg/facebook-scraper\n",
    "    \n",
    "    Args:\n",
    "        fb_group_list(str, list): a list of Facebook pages to scrape, must be public\n",
    "        pages(int): number of pages to collect\n",
    "        cookies_file(str): file location of cookies data\n",
    "        options(dict): dictionary of options for collection, dictionary options can be found in the link above\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: a DataFrame containing comments and associated information from posts scraped. Posts scraped are gathered from 'fb_group_list' posts that \n",
    "                   that contain words inputted in 'words_list'\n",
    "    \"\"\"\n",
    "    # If content in the 'comment_text' column is the commenters name it is most likely because they commented with just a picture and no text\n",
    "    post_list = []\n",
    "    df_comments = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(group = fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            comments_list = []\n",
    "            replies_list = []\n",
    "            \n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "            x = 0\n",
    "                \n",
    "            while x < len(post_list):\n",
    "                comments_list = post_list[x]['comments_full']\n",
    "                x+=1\n",
    "\n",
    "                if comments_list != []:\n",
    "                    i = 0\n",
    "                    comment_text = comments_list[i]['comment_text']\n",
    "\n",
    "                    for comment in comment_text:\n",
    "                        while i < len(comments_list):\n",
    "                            comments_list[i]['comment_text'] = comments_list[i]['comment_text'].split('\\n',1)[0]\n",
    "                            replies_list = comments_list[i]['replies']\n",
    "                            i+=1\n",
    "\n",
    "                            if replies_list != []:\n",
    "                                z = 0\n",
    "\n",
    "                                while z < len(replies_list):\n",
    "                                    replies_list[z]['comment_text'] = replies_list[z]['comment_text'].split('\\n',1)[0]\n",
    "                                    z+=1\n",
    "            df_comments = df_comments.append(comments_list)\n",
    "    print('Done')\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2400f8-f017-4235-a575-3b215c827c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_group_list = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38756b0-0b65-4591-b172-b2302a3fd695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = scrape_comments(fb_group_list, 40, cookies, {\"comments\": True, \"reactors\": True, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96039c66-0367-417c-9bd8-f63686e7ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2bcba-06bb-41c4-a38c-fb391ecb6725",
   "metadata": {},
   "source": [
    "# Scrape FB group posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205af4d6-26cc-4892-86f8-aff603455839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only collects posts\n",
    "def scrape_group_posts(fb_group_list, pages, cookies_file, options):\n",
    "    post_list = []\n",
    "    df_posts = pd.DataFrame()\n",
    "    for fb_group in fb_group_list:\n",
    "        for post in get_posts(group = fb_group, pages = pages, cookies = cookies_file, options = options):\n",
    "            post['text'] = post['text'].split('\\n',1)[0]\n",
    "            print(post['text']+'\\n')\n",
    "            post_list.append(post)\n",
    "        df_posts = df_posts.append(post_list)\n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13157f-50e8-40f8-b325-f021fe7d24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function parameters \n",
    "fb_group_list = ['']\n",
    "cookies = ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd63f9-6771-40d5-8fc9-01d3a04a2a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_posts = scrape_group_posts(fb_group_list, 10000000, cookies, {\"comments\": False, \"allow_extra_requests\": True, 'posts_per_page': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffb87f-9a43-44d4-b775-2de3d01221e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_posts.to_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75558337-a724-468e-948f-1813671148b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
